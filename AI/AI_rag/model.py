import os

from dotenv import load_dotenv
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import JSONLoader, TextLoader
from langchain.memory import ConversationBufferMemory
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_community.chat_models import ChatTongyi
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_core.documents import Document

try:
    from .base_model import BaseModel
    from .utils import safe_print
except (ImportError, ValueError):
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹å¼
    import os
    import sys

    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    from base_model import BaseModel
    from utils import safe_print

load_dotenv()

DASHSCOPE_API_KEY = os.environ["OPENAI_API_KEY"]


class UniversalModel(BaseModel):
    """é€šç”¨æ¨¡å‹ç±»ï¼Œæ”¯æŒå¤šç§æ•°æ®æº"""

    def __init__(self, model_name):
        """
        åŠ è½½é€šç”¨æ¨¡å‹
        :param model_name: æ¨¡å‹åç§°ï¼ˆå¯¹åº”æ–‡ä»¶å¤¹ï¼‰
        """
        super().__init__(model_name)
        if model_name.startswith("model_"):
            model_dir = model_name
        else:
            model_dir = f"model_{model_name}"

        # éªŒè¯æ¨¡å‹ç›®å½•
        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"æ¨¡å‹ç›®å½• {model_dir} ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºæ¨¡å‹")

        print(f"åŠ è½½æ¨¡å‹: {model_name}")

        # 1. åŠ è½½å‘é‡æ•°æ®åº“
        embedding = DashScopeEmbeddings(
            model="text-embedding-v1", dashscope_api_key=DASHSCOPE_API_KEY
        )
        self.db = Chroma(persist_directory=model_dir, embedding_function=embedding)

        # 2. åŠ è½½æç¤ºæ¨¡æ¿
        template_path = f"{model_dir}/prompt_template.txt"
        if os.path.exists(template_path):
            with open(template_path, "r", encoding="utf-8") as f:
                system_template = f.read()
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿ - æ›´è‡ªç„¶çš„æ–‡ç« é£æ ¼æç¤º
            system_template = (
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–è¾‘å’Œä½œå®¶ï¼Œèƒ½å¤Ÿæ ¹æ®æä¾›çš„èµ„æ–™æ’°å†™ç»“æ„æ¸…æ™°ã€å†…å®¹è¯¦å®çš„æ–‡ç« ã€‚"
                "è¯·éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š"
                "1. ä½¿ç”¨è‡ªç„¶æµç•…çš„è¯­è¨€ï¼Œé¿å…ç”Ÿç¡¬çš„åˆ—è¡¨æˆ–ç¼–å·"
                "2. æ–‡ç« åº”æœ‰æ¸…æ™°çš„ç»“æ„ï¼ŒåŒ…æ‹¬å¼•è¨€ã€ä¸»ä½“æ®µè½å’Œç»“è®º"
                "3. ä¸»ä½“éƒ¨åˆ†åº”å›´ç»•å‡ ä¸ªæ ¸å¿ƒè§‚ç‚¹å±•å¼€ï¼Œæ¯ä¸ªè§‚ç‚¹éƒ½è¦æœ‰å……åˆ†çš„ç»†èŠ‚æ”¯æ’‘"
                "4. ä¸è¦ä½¿ç”¨'####'ã€'**'ç­‰Markdownæ ¼å¼æ ‡è®°"
                "5. ä¿æŒå®¢è§‚ã€å‡†ç¡®ï¼ŒåŸºäºæä¾›çš„èµ„æ–™è¿›è¡Œæ’°å†™"
                "6. é¿å…æ¶‰åŠæ•æ„Ÿè¯é¢˜ï¼Œä¿æŒå®¢è§‚ä¸­ç«‹çš„è¯­è°ƒ"
            )

        # 3. åˆ›å»ºæç¤ºæ¨¡æ¿
        messages = [
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template("{question}"),
        ]
        prompt = ChatPromptTemplate.from_messages(messages)

        # 4. åˆ›å»ºè¯­è¨€æ¨¡å‹
        llm = ChatTongyi(
            dashscope_api_key=DASHSCOPE_API_KEY,
            model="qwen-flash",
            temperature=0.2,
            top_p=0.9,
        )

        # 5. åˆ›å»ºæ£€ç´¢é“¾
        retriever = self.db.as_retriever(search_kwargs={"k": 10})
        self.qa = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            memory=ConversationBufferMemory(
                memory_key="chat_history", return_messages=True, output_key="answer"
            ),
            combine_docs_chain_kwargs={"prompt": prompt},
            return_source_documents=True,
        )

        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def generate_summary(self, question: str) -> str:
        """ç”Ÿæˆå†…å®¹æ€»ç»“"""
        result = self.qa({"question": question})
        return result["answer"]

    def ask_question(self, question: str) -> str:
        """å›ç­”å•ä¸ªé—®é¢˜"""
        result = self.qa({"question": question})
        return result["answer"]

    def interactive_qa(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        print("\nğŸ’¬ è¿›å…¥äº¤äº’å¼é—®ç­”æ¨¡å¼ï¼ˆè¾“å…¥'exit'é€€å‡ºï¼‰")
        while True:
            user_input = input("\næ‚¨çš„é—®é¢˜: ")

            if user_input.lower() == "exit":
                print("é—®ç­”ç»“æŸ")
                break

            if not user_input.strip():
                print("é—®é¢˜ä¸èƒ½ä¸ºç©º")
                continue

            # æ‰§è¡ŒæŸ¥è¯¢ï¼Œä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯
            formatted_question = (
                f"è¯·é’ˆå¯¹ä»¥ä¸‹é—®é¢˜æä¾›ä¸€ä¸ªå®¢è§‚ã€ä¸­ç«‹ä¸”ç»“æ„æ¸…æ™°çš„å›ç­”ï¼š{user_input}\n\n"
                "è¦æ±‚ï¼š\n"
                "1. å›ç­”åº”é‡‡ç”¨è‡ªç„¶æµç•…çš„æ•£æ–‡å½¢å¼ï¼Œä¸è¦ä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·\n"
                "2. å›ç­”ç»“æ„åº”åŒ…æ‹¬å¼•è¨€ã€ä¸»ä½“æ®µè½å’Œæ€»ç»“\n"
                "3. ä¸»ä½“éƒ¨åˆ†åº”å›´ç»•å‡ ä¸ªæ ¸å¿ƒè§‚ç‚¹å±•å¼€ï¼Œæ¯ä¸ªè§‚ç‚¹éƒ½è¦æœ‰å……åˆ†çš„ç»†èŠ‚æ”¯æ’‘\n"
                "4. ä½¿ç”¨å‡†ç¡®ã€ä¸“ä¸šçš„è¯­è¨€ï¼Œé¿å…å£è¯­åŒ–è¡¨è¾¾\n"
                "5. ä¸è¦ä½¿ç”¨'####'ã€'**'ç­‰Markdownæ ¼å¼æ ‡è®°\n"
                "6. å›ç­”åº”è¯¦å°½ä½†ä¸å†—é•¿ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®ä¸”æ˜“äºç†è§£\n"
                "7. ä¿æŒå®¢è§‚ä¸­ç«‹çš„è¯­è°ƒï¼Œé¿å…ä¸»è§‚åˆ¤æ–­\n"
                "8. åŸºäºäº‹å®è¿›è¡Œå›ç­”ï¼Œé¿å…æ¨æµ‹æˆ–æœªç»è¯å®çš„è¯´æ³•\n"
                "9. åœ¨å›ç­”ç»“å°¾å¤„ç®€è¦å‘Šè¯‰ç”¨æˆ·ä¿¡æ¯æ¥æº"
            )

            print("\n" + "=" * 40 + f" é—®é¢˜: {user_input} " + "=" * 40)
            try:
                result = self.qa({"question": formatted_question})
                print(f"\nç­”æ¡ˆ: {result['answer']}")
            except Exception as e:
                print(f"\nå›ç­”é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
                print("è¿™å¯èƒ½æ˜¯ç”±äºå†…å®¹å®¡æŸ¥æœºåˆ¶å¯¼è‡´çš„ï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°é—®é¢˜ã€‚")
                continue

            # å¯é€‰ï¼šæ˜¾ç¤ºæ¥æºæ–‡æ¡£
            show_source = input("æ˜¾ç¤ºæ¥æºæ–‡æ¡£? (y/n): ")
            if show_source.lower() == "y":
                print("\næ¥æºæ–‡æ¡£:")
                for i, doc in enumerate(result["source_documents"]):
                    print(f"æ–‡æ¡£ {i+1}:")
                    safe_print(doc.page_content, max_length=200)
                    print("...\n")
